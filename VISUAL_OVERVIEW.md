# ğŸ“Š Integration Overview - Visual Guide

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Your Application                         â”‚
â”‚  (Any client: web, mobile, backend service, etc.)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ HTTP Request
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               N3090 Inference Node (FastAPI)                     â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚        /v1/chat/completions Endpoint                    â”‚  â”‚
â”‚  â”‚  [OpenAI-compatible ChatCompletion Format]              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚                                    â”‚
â”‚                    Is EXTERNAL_LLM_ENABLED=true?                â”‚
â”‚                    â”‚                      â”‚                     â”‚
â”‚              YES â”€â”€â”˜                      â””â”€â”€ NO                â”‚
â”‚              â”‚                              â”‚                   â”‚
â”‚              â–¼                              â–¼                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  External LLM      â”‚        â”‚  Local Model Router  â”‚       â”‚
â”‚  â”‚  Client            â”‚        â”‚  (vLLM, HF, etc)    â”‚       â”‚
â”‚  â”‚                    â”‚        â”‚                      â”‚       â”‚
â”‚  â”‚ â€¢ Try API call     â”‚        â”‚ â€¢ Run local models   â”‚       â”‚
â”‚  â”‚ â€¢ Timeout: 30s     â”‚        â”‚ â€¢ Fast (50-500ms)    â”‚       â”‚
â”‚  â”‚ â€¢ Fallback on err  â”‚        â”‚ â€¢ No external deps   â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚            â”‚                            â”‚                      â”‚
â”‚    Success? â”œâ”€ YES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                      â”‚
â”‚            â”‚                        â”‚  â”‚                      â”‚
â”‚    Error?  â””â”€ NO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€ â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                                    â”‚                      â”‚    â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚    â”‚
â”‚                              â”‚ Wrap Response  â”‚           â”‚    â”‚
â”‚                              â”‚ â€¢ Model name   â”‚           â”‚    â”‚
â”‚                              â”‚ â€¢ Tokens       â”‚           â”‚    â”‚
â”‚                              â”‚ â€¢ Format       â”‚           â”‚    â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚    â”‚
â”‚                                    â”‚                      â”‚    â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                              â”‚                                 â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚                    â”‚  Audit Log Entry       â”‚                 â”‚
â”‚                    â”‚  â€¢ Model used          â”‚                 â”‚
â”‚                    â”‚  â€¢ Tokens              â”‚                 â”‚
â”‚                    â”‚  â€¢ Response time       â”‚                 â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                                      â”‚
     â”œâ”€ Uses Mediqzy API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Mediqzy.com (LLM)
     â”‚                                      â”‚
     â””â”€ Or uses Local Models â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ vLLM / HF Transformers
```

---

## Request/Response Flow

### With External LLM (Mediqzy)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Client Request                                       â”‚
â”‚ {                                                    â”‚
â”‚   "messages": [{"role":"user","content":"..."}],   â”‚
â”‚   "agent_type": "MedicalQA"                         â”‚
â”‚ }                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Check Config     â”‚
        â”‚ ENABLED = true?  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Call Mediqzy API        â”‚
        â”‚ https://api.mediqzy.com â”‚
        â”‚ /v1/chat/completions    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                 â”‚
      SUCCESS           TIMEOUT/ERROR
         â”‚                 â”‚
         â–¼                 â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Use result â”‚   â”‚ Use fallback  â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ (local model) â”‚
         â”‚           â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Wrap in OpenAI    â”‚
        â”‚ Format            â”‚
        â”‚ â€¢ id              â”‚
        â”‚ â€¢ model           â”‚
        â”‚ â€¢ choices         â”‚
        â”‚ â€¢ usage           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Return to Client    â”‚
        â”‚ {                   â”‚
        â”‚   "model":          â”‚
        â”‚   "mediqzy:clinical"â”‚
        â”‚   ...               â”‚
        â”‚ }                   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Configuration Hierarchy

```
DEFAULT VALUES
    â”‚
    â”œâ”€ EXTERNAL_LLM_ENABLED = false (disabled by default)
    â”œâ”€ EXTERNAL_LLM_TEMPERATURE = 0.7
    â”œâ”€ EXTERNAL_LLM_MAX_TOKENS = None (unlimited)
    â””â”€ EXTERNAL_LLM_TIMEOUT = 30 seconds

                 â–¼ Override with â–¼

ENVIRONMENT VARIABLES (takes precedence)
    â”‚
    â”œâ”€ EXTERNAL_LLM_ENABLED = true/false
    â”œâ”€ EXTERNAL_LLM_PROVIDER = mediqzy/openai/custom
    â”œâ”€ EXTERNAL_LLM_BASE_URL = https://api.mediqzy.com
    â”œâ”€ EXTERNAL_LLM_API_KEY = sk-xxxxx
    â”œâ”€ EXTERNAL_LLM_MODEL = mediqzy-clinical
    â”œâ”€ EXTERNAL_LLM_TEMPERATURE = 0.0-1.0
    â”œâ”€ EXTERNAL_LLM_MAX_TOKENS = 512-4096
    â””â”€ EXTERNAL_LLM_TIMEOUT = 10-120

                 â–¼ Applied to â–¼

RUNTIME CONFIGURATION
    â”‚
    â””â”€ LLMConfig object created at startup
       â””â”€ ExternalLLMClient initialized
          â””â”€ Ready to handle requests
```

---

## Supported Providers Map

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     OPENAI-COMPATIBLE LLM PROVIDERS                    â”‚
â”‚     (All work with this implementation)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

CLOUD-BASED PROVIDERS                LOCAL PROVIDERS
â”œâ”€ Mediqzy.com âœ… (Healthcare)       â”œâ”€ Ollama âœ…
â”œâ”€ OpenAI âœ… (General)               â”œâ”€ LM Studio âœ…
â”œâ”€ Anthropic Claude âœ…                â”œâ”€ vLLM âœ…
â”œâ”€ Google PaLM âœ…                     â”œâ”€ LiteLLM âœ…
â”œâ”€ HuggingFace Inference âœ…           â””â”€ FastChat âœ…
â””â”€ Azure OpenAI âœ…

All support the same API:
POST /v1/chat/completions
{
  "model": "model-name",
  "messages": [...],
  "temperature": 0.7,
  "max_tokens": 2048,
  "stream": false
}
```

---

## Feature Availability Matrix

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ Feature            â•‘ Mediqzy    â•‘ OpenAI   â•‘ Local LLM  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ Chat Completion    â•‘ âœ… Yes     â•‘ âœ… Yes   â•‘ âœ… Yes     â•‘
â•‘ Streaming          â•‘ âœ… Yes     â•‘ âœ… Yes   â•‘ âœ… Yes     â•‘
â•‘ Temperature        â•‘ âœ… Yes     â•‘ âœ… Yes   â•‘ âœ… Yes     â•‘
â•‘ Max Tokens         â•‘ âœ… Yes     â•‘ âœ… Yes   â•‘ âœ… Yes     â•‘
â•‘ Token Counting     â•‘ âœ… Yes     â•‘ âœ… Yes   â•‘ âœ… Est.    â•‘
â•‘ Function Calling   â•‘ âœ… Yes     â•‘ âœ… Yes   â•‘ âŒ No      â•‘
â•‘ Embeddings         â•‘ âœ… Yes     â•‘ âœ… Yes   â•‘ âŒ No      â•‘
â•‘ Cost Tracking      â•‘ âœ… Yes     â•‘ âœ… Yes   â•‘ âŒ N/A     â•‘
â•‘ API Key Required   â•‘ âœ… Yes     â•‘ âœ… Yes   â•‘ âŒ No      â•‘
â•‘ Latency (typical)  â•‘ 500-2000ms â•‘ 500-2000â•‘ 50-500ms   â•‘
â•‘ Cost               â•‘ $$$/month  â•‘ $$/monthâ•‘ None       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## Fallback Decision Tree

```
                    â”Œâ”€ Request arrives
                    â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Is external    â”‚
            â”‚ LLM enabled?   â”‚
            â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
           YES  â”‚        â”‚  NO
               â”‚        â”‚
               â–¼        â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Try      â”‚ â”‚ Skip to  â”‚
        â”‚ Mediqzy  â”‚ â”‚ Local    â”‚
        â”‚ API      â”‚ â”‚ Router   â”‚
        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
             â”‚             â”‚
        â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”        â”‚
        â”‚ Success?â”‚        â”‚
        â””â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”˜        â”‚
         YES    NO         â”‚
          â”‚     â”‚          â”‚
          â”‚     â–¼          â”‚
          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
          â”‚  â”‚ Timeout? â”‚  â”‚
          â”‚  â””â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”˜  â”‚
          â”‚   YES   NO     â”‚
          â”‚    â”‚     â”‚     â”‚
          â”‚    â–¼     â–¼     â”‚
          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
          â”‚  â”‚ Fallback toâ”‚â”‚
          â”‚  â”‚ Local      â”‚â”‚
          â”‚  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
          â”‚      â”‚         â”‚
          â””â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Wrap Response    â”‚
        â”‚ â€¢ Model name     â”‚
        â”‚ â€¢ Tokens         â”‚
        â”‚ â€¢ Format         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Return to Client â”‚
        â”‚ (OpenAI format)  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Deployment Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Production Environment                 â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Load Balancer / Reverse Proxy (Nginx)    â”‚   â”‚
â”‚  â”‚  â€¢ Port 443 (HTTPS)                       â”‚   â”‚
â”‚  â”‚  â€¢ Rate limiting                          â”‚   â”‚
â”‚  â”‚  â€¢ Request routing                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                              â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚         â”‚           â”‚           â”‚                 â”‚
â”‚         â–¼           â–¼           â–¼                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚Instanceâ”‚  â”‚Instanceâ”‚  â”‚Instanceâ”‚  (3 replicas)
â”‚  â”‚ 1      â”‚  â”‚ 2      â”‚  â”‚ 3      â”‚  for HA
â”‚  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜              â”‚
â”‚      â”‚           â”‚           â”‚                    â”‚
â”‚      â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”   â”‚                    â”‚
â”‚      â–¼    â”‚      â–¼       â”‚   â–¼                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚   â”‚  Env Vars (from secrets)    â”‚                â”‚
â”‚   â”‚  EXTERNAL_LLM_ENABLED=true  â”‚                â”‚
â”‚   â”‚  EXTERNAL_LLM_BASE_URL=...  â”‚                â”‚
â”‚   â”‚  EXTERNAL_LLM_API_KEY=...   â”‚                â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚          â”‚                                        â”‚
â”‚          â–¼                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚   â”‚ External LLM Routing         â”‚               â”‚
â”‚   â”‚                              â”‚               â”‚
â”‚   â”‚ â”œâ”€ Mediqzy (primary)         â”‚               â”‚
â”‚   â”‚ â””â”€ Local Model (fallback)    â”‚               â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚          â”‚                                        â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                                 â”‚
â”‚    â”‚           â”‚                                 â”‚
â”‚    â–¼           â–¼                                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚ â”‚ Local â”‚   â”‚ Mediqzy.com    â”‚                  â”‚
â”‚ â”‚ LLM   â”‚   â”‚ (External API) â”‚                  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## File Organization

```
/home/dgs/N3090/
â”œâ”€â”€ ğŸ“„ GET_STARTED_5_MIN.md ................. START HERE
â”œâ”€â”€ ğŸ“„ INTEGRATION_COMPLETE.md ............. Overview
â”œâ”€â”€ ğŸ“„ MEDIQZY_QUICK_START.md .............. Quick ref
â”œâ”€â”€ ğŸ“„ MEDIQZY_API_EXAMPLES.md ............. Code samples
â”œâ”€â”€ ğŸ“„ EXTERNAL_LLM_IMPLEMENTATION_SUMMARY.md  Details
â”œâ”€â”€ ğŸ“„ INTEGRATION_VERIFICATION.md ......... QA checklist
â”œâ”€â”€ ğŸ“„ FILE_INDEX.md ....................... Navigation
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ ğŸ“„ EXTERNAL_LLM_INTEGRATION.md ..... Full guide
â”‚
â””â”€â”€ services/inference-node/
    â”œâ”€â”€ ğŸ“„ .env.external_llm.example ....... Config template
    â”œâ”€â”€ app/
    â”‚   â”œâ”€â”€ main.py ........................ Chat endpoint (modified)
    â”‚   â””â”€â”€ services/
    â”‚       â””â”€â”€ external_llm.py ........... LLM client (new)
    â”‚
    â”œâ”€â”€ logs/
    â”‚   â””â”€â”€ inference.log ................. Monitoring
    â”‚
    â””â”€â”€ output/
        â””â”€â”€ tabulations/ .................. PDFs (from earlier phase)
```

---

## Technology Stack

```
Frontend / Client
    â”‚
    â””â”€ HTTP/REST API
         â”‚
    N3090 Backend (FastAPI)
         â”‚
         â”œâ”€ External LLM Routing
         â”‚  â””â”€ httpx (async HTTP client)
         â”‚     â””â”€ Mediqzy / OpenAI / Custom API
         â”‚
         â””â”€ Local Model Routing
            â”œâ”€ vLLM (optimized inference)
            â”œâ”€ HuggingFace Transformers
            â””â”€ Other local backends

Storage:
    â”œâ”€ Logs (inference.log)
    â”œâ”€ Policy Masters (YAML)
    â”œâ”€ Tabulation PDFs (ReportLab)
    â””â”€ Metadata (JSON)

Monitoring:
    â”œâ”€ Prometheus (metrics)
    â”œâ”€ Grafana (dashboards)
    â””â”€ CloudWatch (logs)
```

---

## Response Timeline

```
Client sends request
    â”‚
    0ms â”Œâ”€ FastAPI receives
        â”‚
   50ms â”œâ”€ Check external LLM config
        â”‚
  100ms â”œâ”€ Start external LLM call
        â”‚
  500ms â”œâ”€ ... external LLM thinking ...
        â”‚
 2000ms â”œâ”€ Receive response from Mediqzy
        â”‚
 2050ms â”œâ”€ Wrap in OpenAI format
        â”‚
 2100ms â”œâ”€ Log response
        â”‚
 2110ms â””â”€ Return to client âœ…

Total: ~2.1 seconds (with external LLM)

vs.

Local Model:
 0ms â”Œâ”€ FastAPI receives
 50ms â”œâ”€ Route to local model
100ms â”œâ”€ ... local model thinking ...
400ms â”œâ”€ Receive response
450ms â”œâ”€ Wrap & log
460ms â””â”€ Return to client âœ…

Total: ~0.46 seconds (local only)

Difference acceptable if Mediqzy provides better quality/compliance
```

---

## Summary Diagram

```
                  YOUR APPLICATION
                        â”‚
                        â”‚ POST /v1/chat/completions
                        â–¼
                  N3090 INFERENCE NODE
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚              â”‚              â”‚
    Config Check    Message Validation
         â”‚              â”‚
    ENABLED?         VALID?
         â”‚              â”‚
         â–¼              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”
    â”‚YES / NOâ”‚      â”‚YES    â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜      â””â”€â”€â”€â”¬â”€â”€â”€â”˜
         â”‚              â”‚
         â–¼              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Try External LLM       â”‚
    â”‚  (Mediqzy.com)          â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
         â”‚                â”‚
      SUCCESS          FAIL
         â”‚                â”‚
         â–¼                â–¼
      â”Œâ”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚OKâ”‚         â”‚Fallback  â”‚
      â””â”€â”€â”˜         â”‚Local LLM â”‚
         â”‚         â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ OpenAI    â”‚
        â”‚ Response  â”‚
        â”‚ Format    â”‚
        â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
         TO CLIENT âœ…
```

---

**For detailed information, start with `GET_STARTED_5_MIN.md`** ğŸ“„
