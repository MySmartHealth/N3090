# External LLM Configuration Examples
# Copy to .env and fill in your credentials

# ========================================
# MEDIQZY.COM CONFIGURATION (Healthcare LLM)
# ========================================
# EXTERNAL_LLM_ENABLED=true
# EXTERNAL_LLM_PROVIDER=mediqzy
# EXTERNAL_LLM_BASE_URL=https://api.mediqzy.com
# EXTERNAL_LLM_API_KEY=sk-mediqzy-your-api-key-here
# EXTERNAL_LLM_MODEL=mediqzy-clinical
# EXTERNAL_LLM_TEMPERATURE=0.7
# EXTERNAL_LLM_MAX_TOKENS=2048
# EXTERNAL_LLM_TIMEOUT=30

# ========================================
# OPENAI CONFIGURATION
# ========================================
# EXTERNAL_LLM_ENABLED=true
# EXTERNAL_LLM_PROVIDER=openai
# EXTERNAL_LLM_BASE_URL=https://api.openai.com
# EXTERNAL_LLM_API_KEY=sk-...your-openai-key
# EXTERNAL_LLM_MODEL=gpt-4
# EXTERNAL_LLM_TEMPERATURE=0.7
# EXTERNAL_LLM_MAX_TOKENS=2048

# ========================================
# OLLAMA (LOCAL LLM - No Auth Required)
# ========================================
# EXTERNAL_LLM_ENABLED=true
# EXTERNAL_LLM_PROVIDER=custom
# EXTERNAL_LLM_BASE_URL=http://localhost:11434
# EXTERNAL_LLM_API_KEY=
# EXTERNAL_LLM_MODEL=mistral
# EXTERNAL_LLM_TEMPERATURE=0.7

# ========================================
# LM STUDIO (LOCAL LLM - No Auth Required)
# ========================================
# EXTERNAL_LLM_ENABLED=true
# EXTERNAL_LLM_PROVIDER=custom
# EXTERNAL_LLM_BASE_URL=http://localhost:1234
# EXTERNAL_LLM_API_KEY=
# EXTERNAL_LLM_MODEL=your-loaded-model
# EXTERNAL_LLM_TEMPERATURE=0.7

# ========================================
# DISABLE EXTERNAL LLM (Use Local Models Only)
# ========================================
# EXTERNAL_LLM_ENABLED=false

# =================================================================================
# INSTRUCTIONS:
# =================================================================================
# 1. Uncomment ONE of the above configurations
# 2. Replace placeholders with your actual credentials:
#    - EXTERNAL_LLM_API_KEY: Your API key from the service
#    - EXTERNAL_LLM_BASE_URL: The API endpoint (remove trailing /)
#    - EXTERNAL_LLM_MODEL: The model identifier available in that service
# 3. Start the application:
#    python -m uvicorn app.main:app --host 0.0.0.0 --port 8000
# 4. Test:
#    curl -X POST http://localhost:8000/v1/chat/completions \
#      -H "Content-Type: application/json" \
#      -d '{"messages":[{"role":"user","content":"test"}],"agent_type":"MedicalQA"}'
#
# For detailed instructions, see:
# - MEDIQZY_QUICK_START.md
# - docs/EXTERNAL_LLM_INTEGRATION.md
