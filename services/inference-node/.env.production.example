# ═══════════════════════════════════════════════════════════════════════════════
# PRODUCTION ENVIRONMENT CONFIGURATION
# ═══════════════════════════════════════════════════════════════════════════════
# Copy this file to .env.production and update with your production values
# NEVER commit real secrets to version control!

# ═══════════════════════════════════════════════════════════════════════════════
# DATABASE CONFIGURATION
# ═══════════════════════════════════════════════════════════════════════════════

# PostgreSQL connection (use SSL in production!)
DATABASE_URL=postgresql+asyncpg://medical_ai:CHANGE_ME_STRONG_PASSWORD@postgres.example.com:5432/medical_ai_prod

# Connection pool settings
DB_POOL_SIZE=20
DB_MAX_OVERFLOW=10
DB_POOL_RECYCLE=3600
DB_ECHO=false

# Vector embedding dimension (BGE-large: 1024, OpenAI: 1536)
VECTOR_DIM=1024

# ═══════════════════════════════════════════════════════════════════════════════
# SECURITY & AUTHENTICATION
# ═══════════════════════════════════════════════════════════════════════════════

# JWT Secret - Generate with: python -c "import secrets; print(secrets.token_hex(32))"
JWT_SECRET=GENERATE_WITH_STRONG_RANDOM_STRING_64_CHARS
JWT_ALGORITHM=HS256
JWT_EXPIRY_HOURS=24
ALLOW_INSECURE_DEV=false

# CORS Configuration
CORS_ORIGINS=["https://yourdomain.com", "https://app.yourdomain.com"]

# ═══════════════════════════════════════════════════════════════════════════════
# HUGGINGFACE & TRANSLATION MODELS
# ═══════════════════════════════════════════════════════════════════════════════

# HuggingFace token for gated model access (get from https://huggingface.co/settings/tokens)
HF_TOKEN=hf_CHANGE_ME_YOUR_HF_TOKEN

# Translation model selection
TRANSLATION_MODEL=Rotary

# Translation cache size (translations to keep in memory)
TRANSLATION_CACHE_SIZE=1000

# ═══════════════════════════════════════════════════════════════════════════════
# MODEL SERVER API KEYS
# ═══════════════════════════════════════════════════════════════════════════════

API_KEY_BIMEDIX2_8081=REPLACE_FROM_SECURE_VAULT
API_KEY_TINY_LLAMA_1B_8083=REPLACE_FROM_SECURE_VAULT
API_KEY_OPENINSURANCE_8084=REPLACE_FROM_SECURE_VAULT
API_KEY_BIOMISTRAL_8085=REPLACE_FROM_SECURE_VAULT

# ═══════════════════════════════════════════════════════════════════════════════
# LOGGING & MONITORING
# ═══════════════════════════════════════════════════════════════════════════════

# Logging configuration
LOG_LEVEL=INFO
LOG_FORMAT=json

# Audit logging directory (must be writable by app, backed up regularly)
TRANSLATION_LOG_DIR=/var/log/medical_ai/translations

# Prometheus metrics
PROMETHEUS_ENABLED=true
METRICS_PORT=9090

# ═══════════════════════════════════════════════════════════════════════════════
# SERVER CONFIGURATION
# ═══════════════════════════════════════════════════════════════════════════════

# Server binding
HOST=0.0.0.0
PORT=8000

# Number of worker processes (set to 2x CPU cores)
WORKERS=4

# Request timeouts (seconds)
REQUEST_TIMEOUT=30
SHUTDOWN_TIMEOUT=30

# Rate limiting
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW_SECONDS=60

# ═══════════════════════════════════════════════════════════════════════════════
# DEPLOYMENT METADATA
# ═══════════════════════════════════════════════════════════════════════════════

# Environment designation
ENVIRONMENT=production

# Deployment region
DEPLOYMENT_REGION=us-east-1

# Application version
APP_VERSION=1.0.0

# ═══════════════════════════════════════════════════════════════════════════════
# OPTIONAL: AWS S3 (for audit log backups)
# ═══════════════════════════════════════════════════════════════════════════════

AWS_ENABLED=false
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AUDIT_LOG_S3_BUCKET=medical-ai-audit-logs

# ═══════════════════════════════════════════════════════════════════════════════
# OPTIONAL: SLACK ALERTS
# ═══════════════════════════════════════════════════════════════════════════════

ALERT_ENABLED=false
SLACK_WEBHOOK_URL=
ALERT_ERROR_RATE_THRESHOLD=0.05
ALERT_CACHE_THRESHOLD=0.5

# ═══════════════════════════════════════════════════════════════════════════════
# OPTIONAL: SENTRY ERROR TRACKING
# ═══════════════════════════════════════════════════════════════════════════════

SENTRY_ENABLED=false
SENTRY_DSN=

# ═══════════════════════════════════════════════════════════════════════════════
# SETUP INSTRUCTIONS
# ═══════════════════════════════════════════════════════════════════════════════

# 1. Copy this file: cp .env.production.example .env.production
# 2. Update all CHANGE_ME_ values with production credentials
# 3. Generate strong secrets:
#    JWT_SECRET:  python -c "import secrets; print(secrets.token_hex(32))"
# 4. Set file permissions: chmod 600 .env.production
# 5. Never commit .env.production to version control
# 6. Use environment variables or secure vault (Vault, AWS Secrets Manager, etc.)
# 7. Restart service: systemctl restart medical-ai-inference

# ═══════════════════════════════════════════════════════════════════════════════
